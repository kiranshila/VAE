{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Imports from keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Lambda, Dense, RepeatVector\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import mse\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from os import walk\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(x):\n",
    "    return 1 + 2*np.maximum(0.1*np.log10(x + np.sqrt(np.finfo(float).eps)),-1) #add epsilon to avoid divide by zero\n",
    "\n",
    "def inverseRescale(x):\n",
    "    return np.power(10, (5*(x-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetSounds(keras.utils.Sequence):\n",
    "    def __init__(self, path, batch_size = 20000):\n",
    "        self.file_names = []\n",
    "        for (dirpath, dirnames, filenames) in walk(path):\n",
    "            self.file_names = filenames\n",
    "            break\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.file_names)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_names) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_names = self.file_names[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "        out = np.empty([self.batch_size,173, 513])\n",
    "        for i,file_name in enumerate(batch_names):\n",
    "            print('\\r', 'read ', i, '/', self.batch_size, end='')\n",
    "            y, sr = librosa.load(self.path + file_name)\n",
    "            out[i] = np.abs(np.transpose(librosa.stft(y, n_fft = 1024, hop_length = 512)))\n",
    "        return out.astype('float32',casting='same_kind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read  4095 / 409688"
     ]
    }
   ],
   "source": [
    "x_train = GetSounds('nsynth-valid/audio/',batch_size=(8192 + 4096))[0]\n",
    "x_test = GetSounds('nsynth-test/audio/',batch_size=4096)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick to push the N(0,1) into the back prop inputs\n",
    "def sample(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[1]\n",
    "    dim = K.int_shape(z_mean)[2]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "input_dim = 513\n",
    "intermediate_dim = 64\n",
    "latent_dim = 20\n",
    "\n",
    "# Construct the model\n",
    "x = Input((None, input_dim))\n",
    "\n",
    "# LSTM Encoder\n",
    "h = LSTM(intermediate_dim, return_sequences=True)(x)\n",
    "\n",
    "# Generate Distribution\n",
    "z_mu = LSTM(latent_dim, return_sequences=True)(h)\n",
    "z_log_sigma = LSTM(latent_dim, return_sequences=True)(h)\n",
    "\n",
    "# Sample from Distribution\n",
    "z = Lambda(sample)([z_mu, z_log_sigma])\n",
    "\n",
    "# decoded LSTM layer\n",
    "decoder_h = LSTM(intermediate_dim, return_sequences=True)\n",
    "decoder_mean = LSTM(input_dim, return_sequences=True)\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "\n",
    "# decoded layer\n",
    "x_bar = decoder_mean(h_decoded)\n",
    "\n",
    "# Full Autoencoder\n",
    "vae = Model(x, x_bar)\n",
    "\n",
    "# Encoder, Input -> Latent Space\n",
    "encoder = Model(x, z_mu)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(None, latent_dim))\n",
    "\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "\n",
    "_x_bar = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cost functions\n",
    "def loss(x, x_bar,beta):\n",
    "    xent_loss = mse(x, x_bar)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma))\n",
    "    loss = xent_loss + beta*kl_loss\n",
    "    return loss\n",
    "    \n",
    "vae.add_loss(loss(x,x_bar,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, compile the model!\n",
    "vae.compile(optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 2/24 [=>............................] - ETA: 3s - loss: 13.5967WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time. Check your callbacks.\n",
      "24/24 [==============================] - ETA: 0s - loss: 12.9669WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time. Check your callbacks.\n",
      "24/24 [==============================] - 10s 411ms/step - loss: 12.9669 - val_loss: 13.3062\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 9s 389ms/step - loss: 12.7970 - val_loss: 13.2605\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 9s 388ms/step - loss: 12.7527 - val_loss: 13.2226\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 9s 390ms/step - loss: 12.7463 - val_loss: 13.2271\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 9s 388ms/step - loss: 12.7255 - val_loss: 13.2209\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 9s 389ms/step - loss: 12.7181 - val_loss: 13.1958\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 9s 389ms/step - loss: 12.7109 - val_loss: 13.1879\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 10s 397ms/step - loss: 12.7081 - val_loss: 13.1879\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 10s 402ms/step - loss: 12.7018 - val_loss: 13.1795\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 9s 396ms/step - loss: 12.7007 - val_loss: 13.1785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f88529dc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "vae.fit(x_train,epochs=epochs,validation_data=[x_test], verbose = 1,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_predict(input):\n",
    "    inter = encoder.predict(np.reshape(input, [1, input.shape[0], input.shape[1]]))\n",
    "    return generator.predict(inter)[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(file):\n",
    "    y, sr = librosa.load(file)\n",
    "    S = np.transpose(librosa.stft(y, n_fft = 1024))\n",
    "    S_pred = vae_predict(np.abs(S))*np.exp(1j*np.angle(S))\n",
    "    out = librosa.istft(np.transpose(S_pred))\n",
    "    librosa.output.write_wav('out2.wav', out, sr, norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply('bass_lo.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
