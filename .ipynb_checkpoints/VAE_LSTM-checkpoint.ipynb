{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder - LTSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiran/.local/lib/python3.8/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/kiran/.local/lib/python3.8/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Imports from keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Lambda, Dense, RepeatVector\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import mse\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from os import walk\n",
    "import os\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_sound(data, threshold = 0.0005, per = 0.2):\n",
    "    abs = np.abs(data)\n",
    "    num_has_sound = np.sum(np.where(abs>threshold, 1, 0))\n",
    "    ratio = num_has_sound/data.shape[0]\n",
    "    return ratio >= per\n",
    "\n",
    "    \n",
    "def rescale(x):\n",
    "    return 1 + 2*np.maximum(0.1*np.log10(x + np.sqrt(np.finfo(float).eps)),-1) #add epsilon to avoid divide by zero\n",
    "\n",
    "    \n",
    "def spectrum_format(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    num_of_samples = int((data.shape[0]/2)) + 1\n",
    "    fft_abs = np.abs(fft[0:num_of_samples])/data.shape[0]\n",
    "    return rescale(fft_abs)\n",
    "\n",
    "class GetSounds(keras.utils.Sequence):\n",
    "    def __init__(self, path, batch_size = 20000):\n",
    "        self.file_names = []\n",
    "        for (dirpath, dirnames, filenames) in walk(path):\n",
    "            self.file_names = filenames\n",
    "            break\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.file_names)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.file_names) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_names = self.file_names[self.batch_size*idx:self.batch_size*(idx+1)]\n",
    "        out = np.empty([self.batch_size,124, 513])\n",
    "        for i,file_name in enumerate(batch_names):\n",
    "            out_i = 0\n",
    "            stream = librosa.stream(self.path + file_name,\n",
    "                            block_length=1,\n",
    "                            frame_length=1024,\n",
    "                            hop_length=512)\n",
    "            for chunk in stream:\n",
    "                out[i,out_i] = spectrum_format(chunk)\n",
    "                out_i = out_i + 1\n",
    "        return out.astype('float32',casting='same_kind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Input Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = GetSounds('../nsynth-train/audio/',batch_size=10000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = GetSounds('../nsynth-test/audio/',batch_size=4096)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to build each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization trick to push the N(0,1) into the back prop inputs\n",
    "def sample(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model parameters and construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "input_dim = 513\n",
    "timesteps = 124\n",
    "intermediate_dim = 64\n",
    "latent_dim = 20\n",
    "\n",
    "# Construct the model\n",
    "x = Input(shape=(timesteps, input_dim,))\n",
    "\n",
    "# LSTM Encoder\n",
    "h = LSTM(intermediate_dim)(x)\n",
    "\n",
    "# Generate Distribution\n",
    "z_mu = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "\n",
    "# Sample from Distribution\n",
    "z = Lambda(sample, output_shape=(latent_dim,))([z_mu, z_log_sigma])\n",
    "\n",
    "# decoded LSTM layer\n",
    "decoder_h = LSTM(intermediate_dim, return_sequences=True)\n",
    "decoder_mean = LSTM(input_dim, return_sequences=True)\n",
    "\n",
    "h_decoded = RepeatVector(timesteps)(z)\n",
    "h_decoded = decoder_h(h_decoded)\n",
    "\n",
    "# decoded layer\n",
    "x_bar = decoder_mean(h_decoded)\n",
    "\n",
    "# Full Autoencoder\n",
    "vae = Model(x, x_bar)\n",
    "\n",
    "# Encoder, Input -> Latent Space\n",
    "encoder = Model(x, z_mu)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "_h_decoded = RepeatVector(timesteps)(decoder_input)\n",
    "_h_decoded = decoder_h(_h_decoded)\n",
    "\n",
    "_x_bar = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cost functions\n",
    "def loss(x, x_bar,beta):\n",
    "    xent_loss = mse(x, x_bar)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma))\n",
    "    loss = xent_loss + beta*kl_loss\n",
    "    return loss\n",
    "    \n",
    "vae.add_loss(loss(x,x_bar,1.1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, compile the model!\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Epochs and batch size\n",
    "epochs = 50\n",
    "\n",
    "checkpoint_path = \"training_ltsm/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Model Checkpoint\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    period=1)\n",
    "\n",
    "vae.save_weights(checkpoint_path.format(epoch=0))\n",
    "#vae.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 00001: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 29s 1s/step - loss: 0.0320 - val_loss: 0.0248\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 00002: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0234 - val_loss: 0.0200\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Epoch 00003: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0188\n",
      "Epoch 00004: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0188 - val_loss: 0.0168\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00005: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0151 - val_loss: 0.0158\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0152\n",
      "Epoch 00006: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0137\n",
      "Epoch 00007: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0137 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00008: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0133\n",
      "Epoch 00009: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00010: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00011: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00012: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00013: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00014: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0110\n",
      "Epoch 00015: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00016: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00017: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00018: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00019: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00020: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00021: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00022: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00023: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00024: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00025: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00026: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0105\n",
      "Epoch 00027: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00028: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00029: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00030: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00031: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00032: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00033: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 00034: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00035: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00036: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0099\n",
      "Epoch 00037: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00038: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00039: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00040: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00041: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00042: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 00043: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00044: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00045: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0090\n",
      "Epoch 00046: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 00047: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0096\n",
      "Epoch 00048: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00049: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.0087\n",
      "Epoch 00050: saving model to training_ltsm/cp.ckpt\n",
      "20/20 [==============================] - 27s 1s/step - loss: 0.0087 - val_loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f3df30310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorBoard Callbacks\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train boi\n",
    "vae.fit(x_train,epochs=epochs,validation_data=[x_test], verbose = 1,batch_size=512,callbacks=[tensorboard_callback,cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_predict(input):\n",
    "    inter = encoder.predict(input)\n",
    "    return generator.predict(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseRescale(x):\n",
    "    return np.power(10, (5*(x-1)))\n",
    "\n",
    "def apply_to_chunk(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    num_of_samples = int((data.shape[0]/2)) + 1\n",
    "    fft_abs = np.abs(fft[0:num_of_samples])/data.shape[0]\n",
    "    fft_arg = np.angle(fft[0:num_of_samples])\n",
    "    rescaled = rescale(fft_abs)\n",
    "    predict_abs = inverseRescale(vae_predict(np.reshape(rescaled, [1, 513])))\n",
    "    predict_complex = predict_abs * np.exp(1j * fft_arg)\n",
    "    predict_complex = np.append(predict_complex, np.zeros(data.shape[0] - num_of_samples))\n",
    "    out_complex = np.fft.ifft(predict_complex)\n",
    "    return np.real(out_complex)\n",
    "    \n",
    "def apply_to_file(input_filename, output_filename):\n",
    "    frame_length = 1024\n",
    "    output = np.empty([])\n",
    "    stream = librosa.stream(input_filename,\n",
    "                            block_length=1,\n",
    "                            frame_length=frame_length,\n",
    "                            hop_length=int(frame_length/2))\n",
    "    prev_chunk = np.zeros(frame_length)\n",
    "    up_ramp = 2*np.arange(int(frame_length/2))/frame_length\n",
    "    down_ramp = 1.0 - up_ramp\n",
    "    for chunk in stream:\n",
    "        if chunk.shape[0] == frame_length:\n",
    "            current_chunk = apply_to_chunk(chunk)\n",
    "            output_chunk = current_chunk[0:int(frame_length/2)]*up_ramp + prev_chunk[int(frame_length/2):]*down_ramp\n",
    "            output = np.append(output, output_chunk*frame_length)\n",
    "            prev_chunk = current_chunk\n",
    "    sr = librosa.get_samplerate(input_filename)\n",
    "    librosa.output.write_wav(output_filename, output, sr, norm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(file):\n",
    "      y, sr = librosa.load(file)\n",
    "      S = np.expand_dims(np.transpose(librosa.stft(y, n_fft=1024))[0:124,:],axis=0)\n",
    "      S_pred = vae_predict(np.abs(S))*np.exp(1j*np.angle(S))\n",
    "      out = librosa.istft(np.transpose(S_pred[0,:,:]))\n",
    "      librosa.output.write_wav('out.wav', out, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(\"test_organ.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_file_interp_no_phase(input1_filename, input2_filename, output_filename):\n",
    "    frame_length = 1024\n",
    "    output = np.empty([])\n",
    "    sr = librosa.get_samplerate(input1_filename)\n",
    "    dur = librosa.get_duration(filename = input1_filename)\n",
    "    samples = sr*dur\n",
    "    sample_count = 0\n",
    "    stream1 = librosa.stream(input1_filename,\n",
    "                            block_length=1,\n",
    "                            frame_length=frame_length,\n",
    "                            hop_length=int(frame_length/4))\n",
    "    stream2 = librosa.stream(input2_filename,\n",
    "                            block_length=1,\n",
    "                            frame_length=frame_length,\n",
    "                            hop_length=int(frame_length/4))\n",
    "    \n",
    "    S = np.zeros([513, int(np.floor(4*samples/frame_length) - 1)])\n",
    "    n = 0\n",
    "    for chunk1, chunk2 in zip(stream1, stream2):\n",
    "        if chunk1.shape[0] == frame_length:\n",
    "            state1, fft_arg = state_from_chunk(chunk1)\n",
    "            state2, fft_arg = state_from_chunk(chunk2)\n",
    "            a = sample_count/samples\n",
    "            sample_count += frame_length/4\n",
    "            spec = spec_from_state(a*state1 + (1-a)*state2)\n",
    "            S[:, n] = spec\n",
    "            n = n+1\n",
    "            print(n)\n",
    "    output = librosa.griffinlim(S, hop_length = int(frame_length/4))*frame_length\n",
    "    librosa.output.write_wav(output_filename, output, sr, norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_from_chunk(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    num_of_samples = int((data.shape[0]/2)) + 1\n",
    "    fft_abs = np.abs(fft[0:num_of_samples])/data.shape[0]\n",
    "    fft_arg = np.angle(fft[0:num_of_samples])\n",
    "    rescaled = rescale(fft_abs)\n",
    "    return encoder.predict(np.reshape(rescaled, [1, 513]))[0], fft_arg\n",
    "\n",
    "def chunk_from_state(data, fft_arg, num_of_samples = 513, data_shape = 1024):\n",
    "    predict_abs = inverseRescale(decoder.predict(data))\n",
    "    predict_complex = predict_abs * np.exp(1j * fft_arg)\n",
    "    predict_complex = np.append(predict_complex, np.zeros(data_shape - num_of_samples))\n",
    "    out_complex = np.fft.ifft(predict_complex)\n",
    "    return np.real(out_complex)\n",
    "\n",
    "def spec_from_state(data):\n",
    "    return inverseRescale(decoder.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
